{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIuzds5LLPyC"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkshing/notebooks/blob/main/stable_video_diffusion_img2vid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "# Stable Video Diffusion (image-to-video) Demo\n",
        "This notebook is the demo for the new image-to-video model, Stable Video Diffusion, from [Stability AI](https://stability.ai/) **on Colab free plan**.\n",
        "\n",
        "This was made by [mkshing](https://twitter.com/mk1stats).\n",
        "\n",
        "Visit the following links for the details of Stable Video Diffusion.\n",
        "* Codebase: https://github.com/Stability-AI/generative-models\n",
        "* HF:\n",
        " * SVD 1.0 (14 frames): https://huggingface.co/stabilityai/stable-video-diffusion-img2vid\n",
        " * SVD 1.0 (25 frames): https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt\n",
        " * SVD 1.1 (25 frames): https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt-1-1\n",
        "* LICENSE: [STABLE VIDEO DIFFUSION NON-COMMERCIAL COMMUNITY LICENSE AGREEMENT](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid/blob/main/LICENSE)\n",
        "* Paper: https://stability.ai/research/stable-video-diffusion-scaling-latent-video-diffusion-models-to-large-datasets\n",
        "\n",
        "## Updates\n",
        "### 2024.2.4\n",
        "* Support [Stable Video Diffusion 1.1 Image-to-Video](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt-1-1)\n",
        "\n",
        "### 2023.11.27\n",
        "* Add the other hyper-parameters (`fps_id`, `motion_bucket_id`, `cond_aug`)\n",
        "\n",
        "![000000](https://user-images.githubusercontent.com/33302880/284800538-f856b437-aa1f-4675-ba40-03da3e953358.gif)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "collapsed": true,
        "id": "GjkYl-_MgHaY",
        "outputId": "69775f56-b5cf-4672-a19e-41c518600322",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.6.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (2.9.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (6.0.3)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2025.3.0)\n",
            "Collecting torchmetrics>0.7.0 (from pytorch_lightning)\n",
            "  Using cached torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (25.0)\n",
            "Requirement already satisfied: typing-extensions>4.5.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (4.15.0)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.13.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.20.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.5.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics>0.7.0->pytorch_lightning) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.22.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (3.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.11)\n",
            "Downloading pytorch_lightning-2.6.0-py3-none-any.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch_lightning\n",
            "Successfully installed lightning-utilities-0.15.2 pytorch_lightning-2.6.0 torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aaimSFWfLPgb",
        "collapsed": true,
        "outputId": "0e3ca84b-8876-4d78-b723-b72bbdabcb77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 28 02:39:14 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Cloning into 'generative-models'...\n",
            "remote: Enumerating objects: 1154, done.\u001b[K\n",
            "remote: Counting objects: 100% (544/544), done.\u001b[K\n",
            "remote: Compressing objects: 100% (176/176), done.\u001b[K\n",
            "remote: Total 1154 (delta 424), reused 368 (delta 368), pack-reused 610 (from 5)\u001b[K\n",
            "Receiving objects: 100% (1154/1154), 86.70 MiB | 15.19 MiB/s, done.\n",
            "Resolving deltas: 100% (596/596), done.\n",
            "--2026-01-28 02:39:22--  https://gist.githubusercontent.com/mkshing/4ad40699756d996ba6b3f7934e6ca532/raw/3f0094272c7a2bd3eb5f1a0db91bed582c9e8f01/requirements.txt\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 746 [text/plain]\n",
            "Saving to: ‘requirements.txt’\n",
            "\n",
            "requirements.txt    100%[===================>]     746  --.-KB/s    in 0s      \n",
            "\n",
            "2026-01-28 02:39:22 (51.5 MB/s) - ‘requirements.txt’ saved [746/746]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Collecting clip@ git+https://github.com/openai/CLIP.git (from -r requirements.txt (line 4))\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-install-fucjhqhe/clip_11942ca2e1f64ca28ffd1cfdd33ee5c3\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-install-fucjhqhe/clip_11942ca2e1f64ca28ffd1cfdd33ee5c3\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting black==23.7.0 (from -r requirements.txt (line 2))\n",
            "  Downloading black-23.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==5.1.0 (from -r requirements.txt (line 3))\n",
            "  Downloading chardet-5.1.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: einops>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (0.8.1)\n",
            "Collecting fairscale>=0.4.13 (from -r requirements.txt (line 6))\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fire>=0.5.0 (from -r requirements.txt (line 7))\n",
            "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (2025.3.0)\n",
            "Collecting invisible-watermark>=0.2.0 (from -r requirements.txt (line 9))\n",
            "  Downloading invisible_watermark-0.2.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting kornia==0.6.9 (from -r requirements.txt (line 10))\n",
            "  Downloading kornia-0.6.9-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (3.10.0)\n",
            "Requirement already satisfied: natsort>=8.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (8.4.0)\n",
            "Collecting ninja>=1.11.1 (from -r requirements.txt (line 13))\n",
            "  Using cached ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: omegaconf>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (2.3.0)\n",
            "Collecting open-clip-torch>=2.20.0 (from -r requirements.txt (line 16))\n",
            "  Downloading open_clip_torch-3.2.0-py3-none-any.whl.metadata (32 kB)\n",
            "Collecting opencv-python==4.6.0.66 (from -r requirements.txt (line 17))\n",
            "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (2.2.2)\n",
            "Requirement already satisfied: pillow>=9.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 19)) (11.3.0)\n",
            "Collecting pudb>=2022.1.3 (from -r requirements.txt (line 20))\n",
            "  Downloading pudb-2025.1.5-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting pytorch-lightning==2.0.1 (from -r requirements.txt (line 21))\n",
            "  Downloading pytorch_lightning-2.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 22)) (6.0.3)\n",
            "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 23)) (1.16.3)\n",
            "Collecting streamlit>=0.73.1 (from -r requirements.txt (line 24))\n",
            "  Downloading streamlit-1.53.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting tensorboardx==2.6 (from -r requirements.txt (line 25))\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: timm>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 26)) (1.0.24)\n",
            "Collecting tokenizers==0.12.1 (from -r requirements.txt (line 27))\n",
            "  Downloading tokenizers-0.12.1.tar.gz (220 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.7/220.7 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 28)) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchaudio>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 29)) (2.9.0+cu126)\n",
            "Collecting torchdata==0.6.1 (from -r requirements.txt (line 30))\n",
            "  Downloading https://download.pytorch.org/whl/torchdata-0.6.1-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m330.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchmetrics>=1.0.1 (from -r requirements.txt (line 31))\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: torchvision>=0.15.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 32)) (0.24.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 33)) (4.67.1)\n",
            "Collecting transformers==4.19.1 (from -r requirements.txt (line 34))\n",
            "  Downloading transformers-4.19.1-py3-none-any.whl.metadata (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Ignored the following versions that require a different python version: 0.55.2 Requires-Python <3.5\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement triton==2.0.0 (from versions: 2.2.0, 2.3.0, 2.3.1, 3.0.0, 3.1.0, 3.2.0, 3.3.0, 3.3.1, 3.4.0, 3.5.0, 3.5.1, 3.6.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for triton==2.0.0\u001b[0m\u001b[31m\n",
            "\u001b[0mObtaining file:///content/generative-models\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: sgm\n",
            "  Building editable for sgm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgm: filename=sgm-0.1.0-py3-none-any.whl size=29848 sha256=5efdae020121ace860cf19d3de01326cbbc84df4d17c5600f223119d8fbac464\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-suhg1pxn/wheels/3e/b8/32/b62d7b540aec6064ee85c5ae07a8d4ecd5997fc7b73baaf0ba\n",
            "Successfully built sgm\n",
            "Installing collected packages: sgm\n",
            "Successfully installed sgm-0.1.0\n",
            "Obtaining sdata from git+https://github.com/Stability-AI/datapipelines.git@main#egg=sdata\n",
            "  Cloning https://github.com/Stability-AI/datapipelines.git (to revision main) to ./src/sdata\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Stability-AI/datapipelines.git /content/src/sdata\n",
            "  Resolved https://github.com/Stability-AI/datapipelines.git to commit 8bce77d147033b3a5285b6d45ee85f33866964fc\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: sdata\n",
            "  Running setup.py develop for sdata\n",
            "Successfully installed sdata-0.0.1\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.21)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.13)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.40.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "#@title Setup\n",
        "!nvidia-smi\n",
        "!git clone https://github.com/Stability-AI/generative-models.git\n",
        "# install required packages from pypi\n",
        "# !pip3 install -r generative-models/requirements/pt2.txt\n",
        "# manually install only necesarry packages for colab\n",
        "!wget https://gist.githubusercontent.com/mkshing/4ad40699756d996ba6b3f7934e6ca532/raw/3f0094272c7a2bd3eb5f1a0db91bed582c9e8f01/requirements.txt\n",
        "!pip3 install -r requirements.txt\n",
        "!pip3 install -e generative-models\n",
        "!pip3 install -e git+https://github.com/Stability-AI/datapipelines.git@main#egg=sdata\n",
        "!pip3 install gradio\n",
        "!pip3 install pytorch_lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "mawwnzWX246N",
        "outputId": "adfb4e15-0cb8-4ad9-bdc0-4d858b8e484c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "d822f99c4b4444fba4c124c84a0bd324",
            "d8ff77fdbee748dab57b91d76d26b25c",
            "0b26f37f808346f4a1fdafc92e5835e4",
            "40588d00b6e64f9ea6f14b2c6920a5fa",
            "5f39579a49ff45c1867a53f7157b89bc",
            "2773420390304f439ee2767365f81320",
            "bc6244f398c64507b1dafdd14b7ac460",
            "d3f3b1fba5f642bfb8b425a6ac71c914",
            "f3b908c2de524c4c98e65c7396504fa9",
            "50864e60db8b417383a28585d336a01d",
            "adf63005e3db4943ae524ca5a6ec6efe",
            "5e3d5c2c03e9416a81fe4ba05af4856d",
            "958ae882e4d54c1f93195ec84db2778b",
            "5313eab469a7485b98efc3c35afbe3aa",
            "0371f2c444e347a894ed1227a30c126f",
            "5a9292cb2fe4441587417f0a8d6c5983",
            "439cd95961f04ab689daa749bdd1180d",
            "48844a7c0a8548a6859e51b9c4165006",
            "830e2eb85b7345cea7ef927571551f75",
            "f241465e6a6840e596358125f27e004f"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d822f99c4b4444fba4c124c84a0bd324"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title Login HuggingFace to download weights\n",
        "#@markdown Please make sure to fill in the form in the model cards and accept it.\n",
        "from huggingface_hub import login\n",
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "zWlfaXvPbR1L"
      },
      "outputs": [],
      "source": [
        "#@title Colab hack for SVD\n",
        "# !pip uninstall -y numpy\n",
        "# !pip install -U numpy\n",
        "!mkdir -p /content/scripts/util/detection\n",
        "!ln -s /content/generative-models/scripts/util/detection/p_head_v1.npz /content/scripts/util/detection/p_head_v1.npz\n",
        "!ln -s /content/generative-models/scripts/util/detection/w_head_v1.npz /content/scripts/util/detection/w_head_v1.npz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "v8O2yR3BLHv6",
        "outputId": "0c25139c-7803-4780-c9db-2de72463720b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5f522a72eebe4d57beac93a1e209257a",
            "32321cba37fe414ead1e58110641216d",
            "7496b86ce85a46ed85b273da7b9934b7",
            "9ac4029f31b04dee82a70d8b42e0fe53",
            "b47c2562b93b437cab092f5b13128f69",
            "327807ad72ea4f20a6ed1ea9c0554a43",
            "1ea0675ef74e43e29204293cb3306eb0",
            "b5ff75f2444d48aeb8bbe263b5abe544",
            "a711535c4c984c5fa709ca7c62e2d8f1",
            "438d4c7cdd6e4dca8cc28f7d529a68d0",
            "ad00ff2b376046dfb9b0df6e6dbb77d8"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "svd.safetensors:   0%|          | 0.00/9.56G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f522a72eebe4d57beac93a1e209257a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title Download weights\n",
        "import os\n",
        "import subprocess\n",
        "from huggingface_hub import hf_hub_download\n",
        "version = \"svd\" #@param [\"svd\", \"svd-xt\", \"svd-xt-1-1\"]\n",
        "TYPE2PATH = {\n",
        "    \"svd\": [\"stabilityai/stable-video-diffusion-img2vid\", \"svd.safetensors\"],\n",
        "    \"svd-xt\": [\"stabilityai/stable-video-diffusion-img2vid-xt\", \"svd_xt.safetensors\"],\n",
        "    \"svd-xt-1-1\": [\"stabilityai/stable-video-diffusion-img2vid-xt-1-1\", \"svd_xt_1_1.safetensors\"],\n",
        "}\n",
        "repo_id, fname = TYPE2PATH[version]\n",
        "ckpt_dir = \"/content/checkpoints\"\n",
        "ckpt_path = os.path.join(ckpt_dir, fname)\n",
        "# @markdown This will take several minutes. <br>\n",
        "# @markdown **Reference:**\n",
        "# @markdown * `svd`: [stabilityai/stable-video-diffusion-img2vid](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid) for 14 frames generation\n",
        "# @markdown * `svd-xt`: [stabilityai/stable-video-diffusion-img2vid-xt](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt) for 25 frames generation\n",
        "# @markdown * `svd-xt-1-1`: [stabilityai/stable-video-diffusion-img2vid-xt-1-1](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt-1-1) for 25 frames generation with fixed conditioning at 6FPS and Motion Bucket Id 127\n",
        "\n",
        "os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "if os.path.exists(ckpt_path):\n",
        "  print(\"Already downloaded\")\n",
        "else:\n",
        "  hf_hub_download(\n",
        "      repo_id=repo_id,\n",
        "      filename=fname,\n",
        "      local_dir=ckpt_dir,\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9AZDrh-SUDt2",
        "outputId": "49b29d4e-7857-4a48-eab3-aed32aaadede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pytorch_lightning'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-228358574.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generative-models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msgm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstantiate_from_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnsfw_and_watermark_dectection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeepFloydDataFiltering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/generative-models/sgm/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoencodingEngine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDiffusionEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_configs_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstantiate_from_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0.1.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/generative-models/sgm/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoencodingEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdiffusion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiffusionEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/generative-models/sgm/models/autoencoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_lightning'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "#@title Load Model\n",
        "import sys\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "import torch\n",
        "\n",
        "sys.path.append(\"generative-models\")\n",
        "from sgm.util import default, instantiate_from_config\n",
        "from scripts.util.detection.nsfw_and_watermark_dectection import DeepFloydDataFiltering\n",
        "\n",
        "def load_model(\n",
        "    config: str,\n",
        "    device: str,\n",
        "    num_frames: int,\n",
        "    num_steps: int,\n",
        "    ckpt_path: str = None,\n",
        "):\n",
        "    config = OmegaConf.load(config)\n",
        "    config.model.params.conditioner_config.params.emb_models[\n",
        "        0\n",
        "    ].params.open_clip_embedding_config.params.init_device = device\n",
        "    config.model.params.sampler_config.params.num_steps = num_steps\n",
        "    config.model.params.sampler_config.params.guider_config.params.num_frames = (\n",
        "        num_frames\n",
        "    )\n",
        "    if ckpt_path is not None:\n",
        "        config.model.params.ckpt_path = ckpt_path\n",
        "        print(f\"Changed `ckpt_path` to {ckpt_path}\")\n",
        "    with torch.device(device):\n",
        "        model = instantiate_from_config(config.model).to(device).eval().requires_grad_(False)\n",
        "\n",
        "    filter = DeepFloydDataFiltering(verbose=False, device=device)\n",
        "    return model, filter\n",
        "\n",
        "\n",
        "if version == \"svd\":\n",
        "    num_frames = 14\n",
        "    num_steps = 25\n",
        "    # output_folder = default(output_folder, \"outputs/simple_video_sample/svd/\")\n",
        "    model_config = \"generative-models/scripts/sampling/configs/svd.yaml\"\n",
        "elif \"svd-xt\" in version:\n",
        "    num_frames = 25\n",
        "    num_steps = 30\n",
        "    # output_folder = default(output_folder, \"outputs/simple_video_sample/svd_xt/\")\n",
        "    model_config = \"generative-models/scripts/sampling/configs/svd_xt.yaml\"\n",
        "else:\n",
        "    raise ValueError(f\"Version {version} does not exist.\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, filter = load_model(\n",
        "    model_config,\n",
        "    device,\n",
        "    num_frames,\n",
        "    num_steps,\n",
        "    ckpt_path,\n",
        ")\n",
        "# move models expect unet to cpu\n",
        "model.conditioner.cpu()\n",
        "model.first_stage_model.cpu()\n",
        "# change the dtype of unet\n",
        "model.model.to(dtype=torch.float16)\n",
        "torch.cuda.empty_cache()\n",
        "model = model.requires_grad_(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "x1-dnq0RT95O"
      },
      "outputs": [],
      "source": [
        "# @title Sampling function\n",
        "import math\n",
        "import os\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from einops import rearrange, repeat\n",
        "from fire import Fire\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.transforms import functional as TF\n",
        "\n",
        "from sgm.inference.helpers import embed_watermark\n",
        "from sgm.util import default, instantiate_from_config\n",
        "\n",
        "\n",
        "def get_unique_embedder_keys_from_conditioner(conditioner):\n",
        "    return list(set([x.input_key for x in conditioner.embedders]))\n",
        "\n",
        "\n",
        "def get_batch(keys, value_dict, N, T, device, dtype=None):\n",
        "    batch = {}\n",
        "    batch_uc = {}\n",
        "\n",
        "    for key in keys:\n",
        "        if key == \"fps_id\":\n",
        "            batch[key] = (\n",
        "                torch.tensor([value_dict[\"fps_id\"]])\n",
        "                .to(device, dtype=dtype)\n",
        "                .repeat(int(math.prod(N)))\n",
        "            )\n",
        "        elif key == \"motion_bucket_id\":\n",
        "            batch[key] = (\n",
        "                torch.tensor([value_dict[\"motion_bucket_id\"]])\n",
        "                .to(device, dtype=dtype)\n",
        "                .repeat(int(math.prod(N)))\n",
        "            )\n",
        "        elif key == \"cond_aug\":\n",
        "            batch[key] = repeat(\n",
        "                torch.tensor([value_dict[\"cond_aug\"]]).to(device, dtype=dtype),\n",
        "                \"1 -> b\",\n",
        "                b=math.prod(N),\n",
        "            )\n",
        "        elif key == \"cond_frames\":\n",
        "            batch[key] = repeat(value_dict[\"cond_frames\"], \"1 ... -> b ...\", b=N[0])\n",
        "        elif key == \"cond_frames_without_noise\":\n",
        "            batch[key] = repeat(\n",
        "                value_dict[\"cond_frames_without_noise\"], \"1 ... -> b ...\", b=N[0]\n",
        "            )\n",
        "        else:\n",
        "            batch[key] = value_dict[key]\n",
        "\n",
        "    if T is not None:\n",
        "        batch[\"num_video_frames\"] = T\n",
        "\n",
        "    for key in batch.keys():\n",
        "        if key not in batch_uc and isinstance(batch[key], torch.Tensor):\n",
        "            batch_uc[key] = torch.clone(batch[key])\n",
        "    return batch, batch_uc\n",
        "\n",
        "\n",
        "\n",
        "def sample(\n",
        "    input_path: str = \"assets/test_image.png\",  # Can either be image file or folder with image files\n",
        "    resize_image: bool = False,\n",
        "    num_frames: Optional[int] = None,\n",
        "    num_steps: Optional[int] = None,\n",
        "    fps_id: int = 6,\n",
        "    motion_bucket_id: int = 127,\n",
        "    cond_aug: float = 0.02,\n",
        "    seed: int = 23,\n",
        "    decoding_t: int = 14,  # Number of frames decoded at a time! This eats most VRAM. Reduce if necessary.\n",
        "    device: str = \"cuda\",\n",
        "    output_folder: Optional[str] = \"/content/outputs\",\n",
        "    skip_filter: bool = False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Simple script to generate a single sample conditioned on an image `input_path` or multiple images, one for each\n",
        "    image file in folder `input_path`. If you run out of VRAM, try decreasing `decoding_t`.\n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    path = Path(input_path)\n",
        "    all_img_paths = []\n",
        "    if path.is_file():\n",
        "        if any([input_path.endswith(x) for x in [\"jpg\", \"jpeg\", \"png\"]]):\n",
        "            all_img_paths = [input_path]\n",
        "        else:\n",
        "            raise ValueError(\"Path is not valid image file.\")\n",
        "    elif path.is_dir():\n",
        "        all_img_paths = sorted(\n",
        "            [\n",
        "                f\n",
        "                for f in path.iterdir()\n",
        "                if f.is_file() and f.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]\n",
        "            ]\n",
        "        )\n",
        "        if len(all_img_paths) == 0:\n",
        "            raise ValueError(\"Folder does not contain any images.\")\n",
        "    else:\n",
        "        raise ValueError\n",
        "    all_out_paths = []\n",
        "    for input_img_path in all_img_paths:\n",
        "        with Image.open(input_img_path) as image:\n",
        "            if image.mode == \"RGBA\":\n",
        "                image = image.convert(\"RGB\")\n",
        "            if resize_image and image.size != (1024, 576):\n",
        "                print(f\"Resizing {image.size} to (1024, 576)\")\n",
        "                image = TF.resize(TF.resize(image, 1024), (576, 1024))\n",
        "            w, h = image.size\n",
        "\n",
        "            if h % 64 != 0 or w % 64 != 0:\n",
        "                width, height = map(lambda x: x - x % 64, (w, h))\n",
        "                image = image.resize((width, height))\n",
        "                print(\n",
        "                    f\"WARNING: Your image is of size {h}x{w} which is not divisible by 64. We are resizing to {height}x{width}!\"\n",
        "                )\n",
        "\n",
        "            image = ToTensor()(image)\n",
        "            image = image * 2.0 - 1.0\n",
        "\n",
        "        image = image.unsqueeze(0).to(device)\n",
        "        H, W = image.shape[2:]\n",
        "        assert image.shape[1] == 3\n",
        "        F = 8\n",
        "        C = 4\n",
        "        shape = (num_frames, C, H // F, W // F)\n",
        "        if (H, W) != (576, 1024):\n",
        "            print(\n",
        "                \"WARNING: The conditioning frame you provided is not 576x1024. This leads to suboptimal performance as model was only trained on 576x1024. Consider increasing `cond_aug`.\"\n",
        "            )\n",
        "        if motion_bucket_id > 255:\n",
        "            print(\n",
        "                \"WARNING: High motion bucket! This may lead to suboptimal performance.\"\n",
        "            )\n",
        "\n",
        "        if fps_id < 5:\n",
        "            print(\"WARNING: Small fps value! This may lead to suboptimal performance.\")\n",
        "\n",
        "        if fps_id > 30:\n",
        "            print(\"WARNING: Large fps value! This may lead to suboptimal performance.\")\n",
        "\n",
        "        value_dict = {}\n",
        "        value_dict[\"motion_bucket_id\"] = motion_bucket_id\n",
        "        value_dict[\"fps_id\"] = fps_id\n",
        "        value_dict[\"cond_aug\"] = cond_aug\n",
        "        value_dict[\"cond_frames_without_noise\"] = image\n",
        "        value_dict[\"cond_frames\"] = image + cond_aug * torch.randn_like(image)\n",
        "        value_dict[\"cond_aug\"] = cond_aug\n",
        "        # low vram mode\n",
        "        model.conditioner.cpu()\n",
        "        model.first_stage_model.cpu()\n",
        "        torch.cuda.empty_cache()\n",
        "        model.sampler.verbose = True\n",
        "\n",
        "        with torch.no_grad():\n",
        "            with torch.autocast(device):\n",
        "                model.conditioner.to(device)\n",
        "                batch, batch_uc = get_batch(\n",
        "                    get_unique_embedder_keys_from_conditioner(model.conditioner),\n",
        "                    value_dict,\n",
        "                    [1, num_frames],\n",
        "                    T=num_frames,\n",
        "                    device=device,\n",
        "                )\n",
        "                c, uc = model.conditioner.get_unconditional_conditioning(\n",
        "                    batch,\n",
        "                    batch_uc=batch_uc,\n",
        "                    force_uc_zero_embeddings=[\n",
        "                        \"cond_frames\",\n",
        "                        \"cond_frames_without_noise\",\n",
        "                    ],\n",
        "                )\n",
        "                model.conditioner.cpu()\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "                # from here, dtype is fp16\n",
        "                for k in [\"crossattn\", \"concat\"]:\n",
        "                    uc[k] = repeat(uc[k], \"b ... -> b t ...\", t=num_frames)\n",
        "                    uc[k] = rearrange(uc[k], \"b t ... -> (b t) ...\", t=num_frames)\n",
        "                    c[k] = repeat(c[k], \"b ... -> b t ...\", t=num_frames)\n",
        "                    c[k] = rearrange(c[k], \"b t ... -> (b t) ...\", t=num_frames)\n",
        "                for k in uc.keys():\n",
        "                    uc[k] = uc[k].to(dtype=torch.float16)\n",
        "                    c[k] = c[k].to(dtype=torch.float16)\n",
        "\n",
        "                randn = torch.randn(shape, device=device, dtype=torch.float16)\n",
        "\n",
        "                additional_model_inputs = {}\n",
        "                additional_model_inputs[\"image_only_indicator\"] = torch.zeros(\n",
        "                    2, num_frames\n",
        "                ).to(device, )\n",
        "                additional_model_inputs[\"num_video_frames\"] = batch[\"num_video_frames\"]\n",
        "\n",
        "                for k in additional_model_inputs:\n",
        "                    if isinstance(additional_model_inputs[k], torch.Tensor):\n",
        "                        additional_model_inputs[k] = additional_model_inputs[k].to(dtype=torch.float16)\n",
        "\n",
        "                def denoiser(input, sigma, c):\n",
        "                    return model.denoiser(\n",
        "                        model.model, input, sigma, c, **additional_model_inputs\n",
        "                    )\n",
        "\n",
        "                samples_z = model.sampler(denoiser, randn, cond=c, uc=uc)\n",
        "                samples_z.to(dtype=model.first_stage_model.dtype)\n",
        "                ##\n",
        "\n",
        "                model.en_and_decode_n_samples_a_time = decoding_t\n",
        "                model.first_stage_model.to(device)\n",
        "                samples_x = model.decode_first_stage(samples_z)\n",
        "                samples = torch.clamp((samples_x + 1.0) / 2.0, min=0.0, max=1.0)\n",
        "                model.first_stage_model.cpu()\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "                os.makedirs(output_folder, exist_ok=True)\n",
        "                base_count = len(glob(os.path.join(output_folder, \"*.mp4\")))\n",
        "                video_path = os.path.join(output_folder, f\"{base_count:06d}.mp4\")\n",
        "                writer = cv2.VideoWriter(\n",
        "                    video_path,\n",
        "                    cv2.VideoWriter_fourcc(*\"MP4V\"),\n",
        "                    fps_id + 1,\n",
        "                    (samples.shape[-1], samples.shape[-2]),\n",
        "                )\n",
        "\n",
        "                samples = embed_watermark(samples)\n",
        "                if not skip_filter:\n",
        "                    samples = filter(samples)\n",
        "                else:\n",
        "                    print(\"WARNING: You have disabled the NSFW/Watermark filter. Please do not expose unfiltered results in services or applications open to the public.\")\n",
        "                vid = (\n",
        "                    (rearrange(samples, \"t c h w -> t h w c\") * 255)\n",
        "                    .cpu()\n",
        "                    .numpy()\n",
        "                    .astype(np.uint8)\n",
        "                )\n",
        "                for frame in vid:\n",
        "                    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "                    writer.write(frame)\n",
        "                writer.release()\n",
        "                all_out_paths.append(video_path)\n",
        "    return all_out_paths\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5MdVILPlMUDe"
      },
      "outputs": [],
      "source": [
        "# @title Do the Run!\n",
        "# @markdown Generation takes about 10 mins for 25 frames on T4 (Colab free plan). Please be patient...\n",
        "# @markdown (V100 takes about 3 mins.)\n",
        "import gradio as gr\n",
        "import random\n",
        "\n",
        "\n",
        "def infer(input_path: str, resize_image: bool, n_frames: int, n_steps: int, seed: str, decoding_t: int, fps_id: int, motion_bucket_id: int, cond_aug: float, skip_filter: bool = False) -> str:\n",
        "  if seed == \"random\":\n",
        "    seed = random.randint(0, 2**32)\n",
        "  if version == \"svd-xt-1-1\":\n",
        "    if fps_id != 6:\n",
        "      print(\"[WARNING] svd-xt-1-1 was fine-tuned in fixed conditioning (`fps_id=6`, `motion_bucket_id=127`)! The performance may vary compared to SVD 1.0.\")\n",
        "    if motion_bucket_id != 127:\n",
        "      print(\"[WARNING] svd-xt-1-1 was fine-tuned in fixed conditioning (`fps_id=6`, `motion_bucket_id=127`)! The performance may vary compared to SVD 1.0.\")\n",
        "  seed = int(seed)\n",
        "  output_paths = sample(\n",
        "    input_path=input_path,\n",
        "    resize_image=resize_image,\n",
        "    num_frames=n_frames,\n",
        "    num_steps=n_steps,\n",
        "    fps_id=fps_id,\n",
        "    motion_bucket_id=motion_bucket_id,\n",
        "    cond_aug=cond_aug,\n",
        "    seed=seed,\n",
        "    decoding_t=decoding_t,  # Number of frames decoded at a time! This eats most VRAM. Reduce if necessary.\n",
        "    device=device,\n",
        "    skip_filter=skip_filter,\n",
        "  )\n",
        "  return output_paths[0]\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "  with gr.Column():\n",
        "    image = gr.Image(label=\"input image\", type=\"filepath\")\n",
        "    resize_image = gr.Checkbox(label=\"resize to optimal size\", value=True)\n",
        "    btn = gr.Button(\"Run\")\n",
        "    with gr.Accordion(label=\"Advanced options\", open=False):\n",
        "      n_frames = gr.Number(precision=0, label=\"number of frames\", value=num_frames)\n",
        "      n_steps = gr.Number(precision=0, label=\"number of steps\", value=num_steps)\n",
        "      seed = gr.Text(value=\"random\", label=\"seed (integer or 'random')\",)\n",
        "      decoding_t = gr.Number(precision=0, label=\"number of frames decoded at a time\", value=2)\n",
        "      fps_id = gr.Number(precision=0, label=\"frames per second\", value=6)\n",
        "      motion_bucket_id = gr.Number(precision=0, value=127, label=\"motion bucket id\")\n",
        "      cond_aug = gr.Number(label=\"condition augmentation factor\", value=0.02)\n",
        "      skip_filter = gr.Checkbox(value=False, label=\"skip nsfw/watermark filter\")\n",
        "  with gr.Column():\n",
        "    video_out = gr.Video(label=\"generated video\")\n",
        "  examples = [\n",
        "      [\"https://user-images.githubusercontent.com/33302880/284758167-367a25d8-8d7b-42d3-8391-6d82813c7b0f.png\"],\n",
        "  ]\n",
        "  inputs = [image, resize_image, n_frames, n_steps, seed, decoding_t, fps_id, motion_bucket_id, cond_aug, skip_filter]\n",
        "  outputs = [video_out]\n",
        "  btn.click(infer, inputs=inputs, outputs=outputs)\n",
        "  gr.Examples(examples=examples, inputs=inputs, outputs=outputs, fn=infer)\n",
        "  demo.queue().launch(debug=True, share=True, show_error=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d822f99c4b4444fba4c124c84a0bd324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_bc6244f398c64507b1dafdd14b7ac460"
          }
        },
        "d8ff77fdbee748dab57b91d76d26b25c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3f3b1fba5f642bfb8b425a6ac71c914",
            "placeholder": "​",
            "style": "IPY_MODEL_f3b908c2de524c4c98e65c7396504fa9",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "0b26f37f808346f4a1fdafc92e5835e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_50864e60db8b417383a28585d336a01d",
            "placeholder": "​",
            "style": "IPY_MODEL_adf63005e3db4943ae524ca5a6ec6efe",
            "value": ""
          }
        },
        "40588d00b6e64f9ea6f14b2c6920a5fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_5e3d5c2c03e9416a81fe4ba05af4856d",
            "style": "IPY_MODEL_958ae882e4d54c1f93195ec84db2778b",
            "value": true
          }
        },
        "5f39579a49ff45c1867a53f7157b89bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_5313eab469a7485b98efc3c35afbe3aa",
            "style": "IPY_MODEL_0371f2c444e347a894ed1227a30c126f",
            "tooltip": ""
          }
        },
        "2773420390304f439ee2767365f81320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a9292cb2fe4441587417f0a8d6c5983",
            "placeholder": "​",
            "style": "IPY_MODEL_439cd95961f04ab689daa749bdd1180d",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "bc6244f398c64507b1dafdd14b7ac460": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "d3f3b1fba5f642bfb8b425a6ac71c914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3b908c2de524c4c98e65c7396504fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50864e60db8b417383a28585d336a01d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adf63005e3db4943ae524ca5a6ec6efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e3d5c2c03e9416a81fe4ba05af4856d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "958ae882e4d54c1f93195ec84db2778b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5313eab469a7485b98efc3c35afbe3aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0371f2c444e347a894ed1227a30c126f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "5a9292cb2fe4441587417f0a8d6c5983": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "439cd95961f04ab689daa749bdd1180d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48844a7c0a8548a6859e51b9c4165006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_830e2eb85b7345cea7ef927571551f75",
            "placeholder": "​",
            "style": "IPY_MODEL_f241465e6a6840e596358125f27e004f",
            "value": "Connecting..."
          }
        },
        "830e2eb85b7345cea7ef927571551f75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f241465e6a6840e596358125f27e004f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f522a72eebe4d57beac93a1e209257a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32321cba37fe414ead1e58110641216d",
              "IPY_MODEL_7496b86ce85a46ed85b273da7b9934b7",
              "IPY_MODEL_9ac4029f31b04dee82a70d8b42e0fe53"
            ],
            "layout": "IPY_MODEL_b47c2562b93b437cab092f5b13128f69"
          }
        },
        "32321cba37fe414ead1e58110641216d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_327807ad72ea4f20a6ed1ea9c0554a43",
            "placeholder": "​",
            "style": "IPY_MODEL_1ea0675ef74e43e29204293cb3306eb0",
            "value": "svd.safetensors: 100%"
          }
        },
        "7496b86ce85a46ed85b273da7b9934b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5ff75f2444d48aeb8bbe263b5abe544",
            "max": 9559625980,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a711535c4c984c5fa709ca7c62e2d8f1",
            "value": 9559625980
          }
        },
        "9ac4029f31b04dee82a70d8b42e0fe53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_438d4c7cdd6e4dca8cc28f7d529a68d0",
            "placeholder": "​",
            "style": "IPY_MODEL_ad00ff2b376046dfb9b0df6e6dbb77d8",
            "value": " 9.56G/9.56G [02:03&lt;00:00, 193MB/s]"
          }
        },
        "b47c2562b93b437cab092f5b13128f69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "327807ad72ea4f20a6ed1ea9c0554a43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ea0675ef74e43e29204293cb3306eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5ff75f2444d48aeb8bbe263b5abe544": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a711535c4c984c5fa709ca7c62e2d8f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "438d4c7cdd6e4dca8cc28f7d529a68d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad00ff2b376046dfb9b0df6e6dbb77d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}